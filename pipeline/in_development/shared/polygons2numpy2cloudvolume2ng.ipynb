{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from scipy.interpolate import splprep, splev\n",
    "from scipy import interpolate\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import json\n",
    "from cloudvolume import CloudVolume\n",
    "from taskqueue import LocalTaskQueue\n",
    "import igneous.task_creation as tc\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some paths and variables\n",
    "animal = 'DK46'\n",
    "label = 'cerebellum'\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "PATH = os.path.join(HOME, 'programming/pipeline_utility/src')\n",
    "sys.path.append(PATH)\n",
    "# local imports\n",
    "from pipeline.lib.sqlcontroller import SqlController\n",
    "from pipeline.lib.file_location import FileLocationManager\n",
    "from pipeline.utilities.utilities_cvat_neuroglancer import NumpyToNeuroglancer, calculate_chunks\n",
    "fileLocationManager = FileLocationManager(animal)\n",
    "sqlController = SqlController(animal)\n",
    "from pipeline.utilities.utilities_process import SCALING_FACTOR\n",
    "# vars\n",
    "sections = sqlController.get_sections(animal, 1)\n",
    "num_sections = len(sections)\n",
    "width = sqlController.scan_run.width\n",
    "height = sqlController.scan_run.height\n",
    "scale_xy = sqlController.scan_run.resolution\n",
    "z_scale = sqlController.scan_run.zresolution\n",
    "scales = np.array([scale_xy, scale_xy, z_scale])\n",
    "width = int(width * SCALING_FACTOR)\n",
    "height = int(height * SCALING_FACTOR)\n",
    "aligned_shape = np.array((width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = sqlController.get_distinct_structures(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### fetch the data\n",
    "rows = sqlController.get_annotations_by_structure(animal, 1, label, FK_structure_id)\n",
    "polygons = defaultdict(list)\n",
    "\n",
    "for row in rows:\n",
    "    xy = (row.x/scale_xy, row.y/scale_xy)\n",
    "    z = int(np.round(row.z/z_scale))\n",
    "    polygons[z].append(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### loop through all the sections and write to a template, then add that template to the volume\n",
    "volume = np.zeros((aligned_shape[1], aligned_shape[0], num_sections), dtype=np.uint8)\n",
    "color = 100\n",
    "for section,points in polygons.items():\n",
    "    template = np.zeros((aligned_shape[1], aligned_shape[0]), dtype=np.uint8)\n",
    "    points = np.array(points)\n",
    "    points = np.round(points*SCALING_FACTOR)\n",
    "    points = points.astype(np.int32)\n",
    "    # cv2.polylines(template, [points], True, color, 8, lineType=cv2.LINE_AA)\n",
    "    cv2.fillPoly(template, pts = [points], color = color)\n",
    "\n",
    "    volume[:, :, section - 1] = template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING, see how it loooks on one section\n",
    "for section,points in polygons.items():\n",
    "    if section == 101:\n",
    "        filename = '/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/DK46/preps/CH1/thumbnail_aligned/101.tif'\n",
    "        template = cv2.imread(filename)\n",
    "        points = np.array(points)\n",
    "        points = np.round(points*SCALING_FACTOR)\n",
    "        points = points.astype(np.int32)\n",
    "        #print(points)\n",
    "        # result = cv2.polylines(template, [points], True, (255,255,0), 8, lineType=cv2.LINE_AA)\n",
    "        cv2.fillPoly(template, pts = [points], color = 200)\n",
    "        plt.figure(figsize = (15, 10))        \n",
    "        plt.imshow(template, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### set variables for mesh/segmentation. the scales are for a regular neurotrace 0.325nm,0.325nm,20um brain\n",
    "scales = (10400, 10400, 20000)\n",
    "# Voxel offset\n",
    "offset = (0, 0, 0)\n",
    "data_type = str(volume.dtype)\n",
    "layer_type = 'segmentation'\n",
    "chunks = [64, 64, 64]\n",
    "num_channels = 1\n",
    "downsample = True\n",
    "\n",
    "OUTPUT_DIR = os.path.join(fileLocationManager.neuroglancer_data, label)\n",
    "\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    shutil.rmtree(OUTPUT_DIR)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "# swap axes for neuroglancer viewing\n",
    "volume = np.swapaxes(volume, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### initialize the Cloudvolume\n",
    "cloudpath = f'file://{OUTPUT_DIR}'\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels = num_channels,\n",
    "    layer_type = layer_type,\n",
    "    data_type = str(volume.dtype), # Channel images might be 'uint8'\n",
    "    encoding = 'raw', # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution = scales, # Voxel scaling, units are in nanometers\n",
    "    voxel_offset = offset, # x,y,z offset in voxels from the origin\n",
    "    chunk_size = chunks, # units are voxels\n",
    "    volume_size = volume.shape, # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol = CloudVolume(cloudpath, mip=0, info=info, compress=True)\n",
    "vol.commit_info()\n",
    "vol[:, :, :] = volume[:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create json for neuroglancer info files\n",
    "cv = CloudVolume(cloudpath, 0)\n",
    "cv.info['segment_properties'] = 'names'\n",
    "cv.commit_info()\n",
    "\n",
    "segment_properties_path = os.path.join(cloudpath.replace('file://', ''), 'names')\n",
    "os.makedirs(segment_properties_path, exist_ok=True)\n",
    "\n",
    "info = {\n",
    "    \"@type\": \"neuroglancer_segment_properties\",\n",
    "    \"inline\": {\n",
    "        \"ids\": [str(color)],\n",
    "        \"properties\": [{\n",
    "            \"id\": \"label\",\n",
    "            \"type\": \"label\",\n",
    "            \"values\": [str(color)]\n",
    "        }]\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(segment_properties_path, 'info'), 'w') as file:\n",
    "    json.dump(info, file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1st create mesh\n",
    "mse = 40\n",
    "tq = LocalTaskQueue(parallel=1)\n",
    "mesh_dir = f'mesh_mip_0_err_{mse}'\n",
    "cv.info['mesh'] = mesh_dir\n",
    "cv.commit_info()\n",
    "tasks = tc.create_meshing_tasks(cv.layer_cloudpath, mip=0, mesh_dir=mesh_dir, max_simplification_error=mse)\n",
    "tq.insert(tasks)\n",
    "tq.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 2nd mesh task, create manifest\n",
    "tasks = tc.create_mesh_manifest_tasks(cv.layer_cloudpath, mesh_dir=mesh_dir)\n",
    "tq.insert(tasks)\n",
    "tq.execute()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
